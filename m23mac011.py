# -*- coding: utf-8 -*-
"""M23MAC011

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/m23mac011-b4b994b2-3b04-4b59-8340-b07f8935b872.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240319/auto/storage/goog4_request%26X-Goog-Date%3D20240319T183016Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4096db8f506bbd87cb4f873ac0eabbcae1d60c751a59242ddefee74236ecb272b9e931b3950c818f1ec2c1e1734008f3db1447d6f4517206accff382f0ae9e0a4bdffd1f7faa7c38fa4ceb4012837bcb083aa7fba6d8bcaaf87b1131d8b22f6e9abc2ac09780a96e090a1ccc47d28bc6ae0e0e1d10e1a62f7609d94b279da2cceb0fcf5d0fc1a3cd524ba952829039da6a6eb63853ab1c3fb5ac7ba427c7a1dbcf7eb230f89b2302f662ace8f81686019009b9e9b944b8fbd4ec18a2d249eaac8b6ee4f16c63e1c9f649c68d8f16da5dab6bf3152734e5b4021c878dc7f63d2e4c295d10f1873f7a216a0a4266b0fdae72805e8e592d2d2e626b4f97ffe66465
"""

import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from pathlib import Path
import os
from PIL import Image
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import albumentations as A
from albumentations.pytorch import ToTensorV2
from torch.optim.lr_scheduler import ReduceLROnPlateau
import matplotlib.pyplot as plt
import numpy as np
import torch
import random
import torch.nn.functional as F

path = Path('/kaggle/input/ISIC 2016')

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class CustomDecoder(nn.Module):
    def __init__(self, num_classes):
        super(CustomDecoder, self).__init__()

        self.conv1 =  nn.ConvTranspose2d(1280, 512, kernel_size=4, stride=2, padding=1)
        self.bn1 = nn.BatchNorm2d(512)
        self.conv2 = nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1)
        self.bn2 = nn.BatchNorm2d(256)
        self.conv3 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)
        self.bn3 = nn.BatchNorm2d(128)
        self.conv4 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)
        self.bn4 = nn.BatchNorm2d(64)
        self.conv5 =  nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)
        self.bn5 = nn.BatchNorm2d(32)
        self.conv6 = nn.Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
        self.sigmoid = nn.Sigmoid()
        self.relu = nn.ReLU(inplace = True)
        self.dropout = nn.Dropout(p = 0.5)


    def forward(self, x):


        x = self.bn1(self.relu(self.conv1(x)))
        x = self.dropout(x)
        x = self.bn2(self.relu(self.conv2(x)))
        x = self.dropout(x)
        x = self.bn3(self.relu(self.conv3(x)))
        x = self.dropout(x)
        x = self.bn4(self.relu(self.conv4(x)))
        x = self.dropout(x)
        x = self.bn5(self.relu(self.conv5(x)))
        x = self.dropout(x)


        x = self.sigmoid(self.conv6(x))
        return x



class ISIC2016Dataset(Dataset):
    def __init__(self, root_dir, mode='train', transform=None):
        self.root_dir = root_dir
        self.mode = mode
        self.transform = transform

        if self.mode == 'train':
            self.images_dir = os.path.join(root_dir, 'train')
            self.masks_dir = os.path.join(root_dir, 'train_masks')
        elif self.mode == 'test':
            self.images_dir = os.path.join(root_dir, 'test')
            self.masks_dir = os.path.join(root_dir, 'test_masks')

        self.image_files = sorted(os.listdir(self.images_dir))
        self.mask_files = sorted(os.listdir(self.masks_dir))

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = os.path.join(self.images_dir, self.image_files[idx])
        mask_name = os.path.join(self.masks_dir, self.mask_files[idx])

        image = Image.open(img_name)
        mask = Image.open(mask_name)
        image = np.array(image)
        mask = np.array(mask)
        mask[mask==255.0] = 1.0

        if self.transform:
            augmentation = self.transform(image=image, mask=mask)
            image = augmentation["image"]
            mask = augmentation["mask"]
            mask = torch.unsqueeze(mask,0)
        return image,mask

train_transform = A.Compose([A.Resize(128,128),
                             A.Rotate(limit=15,p=0.1),
                             A.HorizontalFlip(p=0.5),
                             A.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5),max_pixel_value=255),
                             ToTensorV2()])

val_transform = A.Compose([A.Resize(128,128),
                           A.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5),max_pixel_value=255),
                           ToTensorV2()])

# Define test dataset and dataloader
root_dir = path
train_dataset = ISIC2016Dataset(root_dir, mode='train', transform=train_transform)
train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)

test_dataset = ISIC2016Dataset(root_dir, mode='test', transform=val_transform)
test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)

def compute_iou_and_dice(encoder, decoder, data_loader, criterion, device="cuda"):
    iou = 0
    dice = 0
    loss = 0
    with torch.no_grad():

        for i, (image, mask) in enumerate(data_loader):

            image = image.float().to(device)
            mask = mask.float().to(device)

            pred = encoder(image)
            mask_pred = decoder(pred)

            #Calculate loss
            loss_batch = criterion(mask_pred, mask)
            loss += loss_batch.item()

            # Calculate iou
            intersection = (mask * mask_pred).sum()
            union = (mask + mask_pred).sum()
            iou += (intersection / (union - intersection)).item()

            # Calculate Dice score
            dice += (2 * intersection / (mask.sum() + mask_pred.sum())).item()

    return iou / len(data_loader), dice / len(data_loader), loss / len(data_loader)

def train_model(encoder, decoder, num_epochs, train_loader, valid_loader, criterion,
                enoptimizer,deoptimizer, device,scheduler=None, scheduler_on='valid_loss'): # valid_loss or train_loss

    iou_list, valid_loss_list,train_loss_list, dice_list = [], [],  [], []

    for epoch in range(num_epochs):

        batch_loss_list = []
        encoder.train()
        decoder.train()
        for batch_idx, (image, mask) in enumerate(train_loader):

            image = image.float().to(device)
            mask = mask.float().to(device)

            # FORWARD AND BACK PROP
            pred = encoder(image)
            mask_pred = decoder(pred)

            loss = criterion(mask_pred,mask)
            enoptimizer.zero_grad()
            deoptimizer.zero_grad()

            loss.backward()

            # UPDATE MODEL PARAMETERS
            enoptimizer.step()
            deoptimizer.step()

            # LOGGING
            batch_loss_list.append(loss.item())

        encoder.eval()
        decoder.eval()
        with torch.no_grad():  # save memory during inference
            train_loss =  sum(batch_loss_list) / len(batch_loss_list)
            iou, dice, valid_loss = compute_iou_and_dice(encoder, decoder, valid_loader, criterion, device=device)
            print(f'Epoch: {epoch+1:02d}/{num_epochs:02d} '
                  f'| IOU Score: {iou :.4f} '
                  f'| Dice Score: {dice :.4f} '
                  f'| Training Loss: {train_loss :.4f} '
                  f'| Validation Loss: {valid_loss :.4f} ')
            iou_list.append(iou)
            valid_loss_list.append(valid_loss)
            train_loss_list.append(train_loss)
            dice_list.append(dice)

        if scheduler is not None:

            if scheduler_on == 'valid_loss':
                scheduler.step(valid_loss_list[-1])
            elif scheduler_on == 'train_loss':
                scheduler.step(train_loss_list[-1])
            else:
                raise ValueError(f'Invalid `scheduler_on` choice.')

    return iou_list, dice_list, valid_loss_list, train_loss_list

def plot_img_mask_pred(dataset, encoder=None, decoder = None, device = "cuda"):
#     if not index:
    index = random.randint(0, len(dataset) - 1)

    image = dataset[index][0].permute(1,2,0)
    mask = dataset[index][1].permute(1,2,0)


    img_to_pred = dataset[index][0].unsqueeze(0).type(torch.float32).to(device)
    pred = encoder(img_to_pred)
    pred = decoder(pred)
    pred = pred.squeeze(0).cpu().detach().permute(1,2,0)
    pred[pred <= 0.8]=0
    pred[pred > 0.8]=1


    # Plot the image
    plt.figure(figsize=(12, 4))
    plt.subplot(1, 3, 1)
    plt.imshow(image)
    plt.title("Image")

    # Plot the mask
    plt.subplot(1, 3, 2)
    plt.imshow(mask, cmap='gray')
    plt.title("Mask")

    # Plot the predicted mask
    plt.subplot(1, 3, 3)
    plt.imshow(pred, cmap='gray')
    plt.title("Prediction")

    # Show the plots
    plt.tight_layout()
    plt.show()

def plot_loss_accuracy(train_loss_list, val_loss_list, val_acc_list, iou_score):

    num_epochs = len(train_loss_list)

    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(6, 12))

    ax1.plot(np.arange(1, num_epochs+1), train_loss_list, color="green", label='Train Loss')
    ax1.plot(np.arange(1, num_epochs+1), val_loss_list, color="red", label='Validation Loss')
    ax1.set_title('Loss')
    ax1.set_xlabel("Epochs")
    ax1.set_ylabel("Loss")
    ax1.legend()
    ax1.legend()

    ax2.plot(np.arange(1, num_epochs+1), val_acc_list, color="blue", label='Dice Score')
    ax2.set_title('Dice Score')
    ax2.set_xlabel("Epochs")
    ax2.set_ylabel('Score')
    ax2.legend()

    ax3.plot(np.arange(1, num_epochs+1), iou_score, color="orange", label='IOU Score')
    ax3.set_title('IOU Score')
    ax3.set_xlabel("Epochs")
    ax3.set_ylabel('Score')
    ax3.legend()

    plt.tight_layout()
    plt.show()

class DiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(DiceLoss, self).__init__()

    def forward(self, inputs, targets, smooth=1):


        #flatten label and prediction tensors
        inputs = inputs.view(-1)
#         print(inputs.size())
        targets = targets.view(-1)

        intersection = (inputs * targets).sum()
        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)

        return 1 - dice

#Experiment 1

criterion = DiceLoss()


# Load pretrained MobileNet encoder
encoder1 = torchvision.models.mobilenet_v2(pretrained =True).features.to(device)

# Load decoder
decoder1 = CustomDecoder(1).to(device)


encoder_params = encoder1.parameters()
decoder_params = decoder1.parameters()

# Define optimizer
en_optimizer = optim.Adam(encoder_params, lr= 0)
de_optimizer = optim.Adam(decoder_params, lr= 0.001)

scheduler = ReduceLROnPlateau(de_optimizer, factor=0.1, patience=4, mode='min', verbose=True)

epochs = 20

iou_lst1, dice_lst1, valid_loss_lst1, train_loss_list1 = train_model(encoder1, decoder1, epochs, train_dataloader, test_dataloader,
                                criterion, en_optimizer, de_optimizer,device,scheduler=scheduler, scheduler_on='train_loss')


# # Save the trained model
torch.save(encoder1.state_dict(), 'encoder_model1.pth')
torch.save(decoder1.state_dict(), 'decoder_model1.pth')

#Experiment 1 results
for i in range(10):
    plot_img_mask_pred(test_dataset, encoder = encoder1, decoder = decoder1, device = "cuda")
plot_loss_accuracy(train_loss_list1, valid_loss_lst1, dice_lst1, iou_lst1)

#Experiment 2

criterion = DiceLoss()


# Load pretrained MobileNet encoder
encoder2 = torchvision.models.mobilenet_v2(pretrained =True).features.to(device)

# Load decoder
decoder2 = CustomDecoder(1).to(device)

encoder_params = encoder2.parameters()
decoder_params = decoder2.parameters()

# Define optimizer
en_optimizer = optim.Adam(encoder_params, lr= 5e-5)
de_optimizer = optim.Adam(decoder_params, lr= 0.001)

scheduler = ReduceLROnPlateau(de_optimizer, factor=0.1, patience=4, mode='min', verbose=True)

epochs = 20

iou_lst2, dice_lst2, valid_loss_lst2, train_loss_list2 = train_model(encoder2, decoder2, epochs, train_dataloader, test_dataloader,
                                criterion, en_optimizer, de_optimizer,device,scheduler=scheduler, scheduler_on='train_loss')


# # Save the trained model
torch.save(encoder2.state_dict(), 'encoder_model2.pth')
torch.save(decoder2.state_dict(), 'decoder_model2.pth')

#Experiment 2 results
for i in range(10):
    plot_img_mask_pred(test_dataset, encoder = encoder2, decoder = decoder2, device = "cuda")
plot_loss_accuracy(train_loss_list2, valid_loss_lst2, dice_lst2, iou_lst2)





